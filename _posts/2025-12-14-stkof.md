---
title: STKOF
date: 2025-12-14 17:00:00 +0000
categories: [CTF, Upsolve]
tags: [pwnable]
math: true
mermaid: true
media_subpath: /assets/posts/2025-12-14-Stkof
image:
  path: preview.png
---

## STKOF

### Overview

**STKOF** is a classic heap exploitation challenge from *HITCON CTF 2014*, targeting *glibc 2.23*. The binary contains a heap-based overflow vulnerability that allows corruption of adjacent chunk metadata. By abusing this corruption, we can perform the safe unlink attack, leading to arbitrary read/write.

Using this primitive, we leak the libc address and overwrite the GOT entry of *free* with *system*, ultimately achieving code execution and spawning a shell.

Challenge files are available [here](https://github.com/guyinatuxedo/nightmare/tree/master/modules/30-unlink/hitcon14_stkof).

### Program Analysis

We are provided with the executable *stkof* and the corresponding libc file *libc-2.23.so*.

Since the binary is dynamically linked and uses our system libc by default, we need to patch it to use the provided libc. This can be done using pwninit:

```bash
pwninit --bin stkof --libc libc-2.23.so --no-template
```

Checking the file type and enabled protections, we get the following:

```bash
~/Desktop/BinExp/Challs/HEAP/Stkof ❯ file stkof
stkof: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.32, BuildID[sha1]=4872b087443d1e52ce720d0a4007b1920f18e7b0, stripped
                                                                                                                                                                                             
~/Desktop/BinExp/Challs/HEAP/Stkof ❯ checksec stkof
[*] '/home/mark/Desktop/BinExp/Challs/HEAP/Stkof/stkof'
    Arch:       amd64-64-little
    RELRO:      Partial RELRO
    Stack:      Canary found
    NX:         NX enabled
    PIE:        No PIE (0x400000)
```

Shows the standard you'd expect... except that it has *Partial RELRO* enabled meaning the *Global Offset Table (GOT)* is writable and *Position Independent Executable (PIE)* is disabled.

Running the patched binary to get a high-level idea of its behavior:

```bash
~/Desktop/BinExp/Challs/HEAP/Stkof ❯ ./stkof_patched
asdf
FAIL
help
FAIL
haha
FAIL
exit
FAIL
1
^C

```

Notice how it keeps printing *FAIL* regardless of the data we provide.

### Reversing

In order to understand this binary logic we need to reverse engineer it. Note that the binary is stripped, so any decompilation shown later is based on manually reconstructed pseudocode and renamed functions.

Here's the *main* function:

```c
__int64 __fastcall main(int a1, char **a2, char **a3)
{
  int choice; // eax
  int v1; // [rsp+Ch] [rbp-74h]
  char nptr[104]; // [rsp+10h] [rbp-70h] BYREF
  unsigned __int64 v7; // [rsp+78h] [rbp-8h]

  v7 = __readfsqword(0x28u);
  alarm(120u);
  while ( fgets(nptr, 10, stdin) )
  {
    choice = atoi(nptr);
    if ( choice == 2 )
    {
      v1 = edit_chunk();
      goto err;
    }
    if ( choice > 2 )
    {
      if ( choice == 3 )
      {
        v1 = delete_chunk();
        goto err;
      }
      if ( choice == 4 )
      {
        v1 = write_chunk();
        goto err;
      }
    }
    else if ( choice == 1 )
    {
      v1 = allocate_chunk();
      goto err;
    }
    v1 = -1;
err:
    if ( v1 )
      puts("FAIL");
    else
      puts("OK");
    fflush(stdout);
  }
  return 0LL;
}
```

It simply sets up a 120-second timer and then enters a while loop where it reads the user’s choice and calls the corresponding function.

*allocate_chunk* function:

```c
__int64 allocate_chunk()
{
  __int64 size; // [rsp+0h] [rbp-80h]
  char *ptr; // [rsp+8h] [rbp-78h]
  char s[104]; // [rsp+10h] [rbp-70h] BYREF
  unsigned __int64 v4; // [rsp+78h] [rbp-8h]

  v4 = __readfsqword(0x28u);
  fgets(s, 16, stdin);
  size = atoll(s);
  ptr = (char *)malloc(size);
  if ( !ptr )
    return 0xFFFFFFFFLL;
  chunk[++idx] = ptr;
  printf("%d\n", idx);
  return 0LL;
}
```

- The function allocates heap memory using a user-controlled size.
- If malloc fails, the function returns -1.
- On success, the returned pointer is stored in the global chunk array.
- The index *idx* is incremented before use, meaning chunk indexing starts at 1, not 0.

*edit_chunk* function:

```c
__int64 edit_chunk()
{
  int i; // eax
  unsigned int idx; // [rsp+8h] [rbp-88h]
  __int64 size; // [rsp+10h] [rbp-80h]
  char *ptr; // [rsp+18h] [rbp-78h]
  char buf[104]; // [rsp+20h] [rbp-70h] BYREF
  unsigned __int64 v6; // [rsp+88h] [rbp-8h]

  v6 = __readfsqword(0x28u);
  fgets(buf, 16, stdin);
  idx = atol(buf);
  if ( idx > 0x100000 )
    return 0xFFFFFFFFLL;
  if ( !chunk[idx] )
    return 0xFFFFFFFFLL;
  fgets(buf, 16, stdin);
  size = atoll(buf);
  ptr = chunk[idx];
  for ( i = fread(ptr, 1uLL, size, stdin); i > 0; i = fread(ptr, 1uLL, size, stdin) )
  {
    ptr += i;
    size -= i;
  }
  if ( size )
    return 0xFFFFFFFFLL;
  else
    return 0LL;
}
```

- The function takes a *chunk index* and a *user-controlled* size.
- It ensures that *idx* is within the bounds of the *chunk* array.
- Data is written directly into `chunk[idx]` using *fread* (if it exists..), which allows *arbitrary-length* writes as we control the *size*.
- Because *ptr* is incremented while *size* is decremented, the function continues writing until all requested bytes are consumed.

*delete_chunk* function:

```c
__int64 delete_chunk()
{
  unsigned int idx; // [rsp+Ch] [rbp-74h]
  char buf[104]; // [rsp+10h] [rbp-70h] BYREF
  unsigned __int64 v3; // [rsp+78h] [rbp-8h]

  v3 = __readfsqword(0x28u);
  fgets(buf, 16, stdin);
  idx = atol(buf);
  if ( idx > 0x100000 )
    return 0xFFFFFFFFLL;
  if ( !chunk[idx] )
    return 0xFFFFFFFFLL;
  free(chunk[idx]);
  chunk[idx] = 0LL;
  return 0LL;
}
```

- The function takes a *chunk index*.
- It ensures that *idx* is within the bounds of the *chunk* array.
- And *frees* the memory stored in *chunk* at index *idx*.
- It also clears the pointer stored there.

*write_chunk* function:

```c
__int64 write_chunk()
{
  unsigned int idx; // [rsp+Ch] [rbp-74h]
  char s[104]; // [rsp+10h] [rbp-70h] BYREF
  unsigned __int64 v3; // [rsp+78h] [rbp-8h]

  v3 = __readfsqword(0x28u);
  fgets(s, 16, stdin);
  idx = atol(s);
  if ( idx > 0x100000 )
    return 0xFFFFFFFFLL;
  if ( !chunk[idx] )
    return 0xFFFFFFFFLL;
  if ( strlen(chunk[idx]) <= 3 )
    puts("//TODO");
  else
    puts("...");
  return 0LL;
}
```

- The function takes a chunk index and verifies that it is within bounds and points to a valid entry in the chunk array.
- It then checks the length of the data stored at `chunk[idx]` using strlen.
- If the length is less than or equal to 3, it prints "//TODO"; otherwise, it prints "...".

Despite its name, this function does not print the contents of the chunk. Instead, it only inspects the length of the stored data and prints a placeholder message.

### Exploitation

#### So, what's the vulnerability?

The vulnerability is a *heap-based buffer overflow* in the *edit_chunk* function. The function uses a user‑controlled size and writes up to n bytes into the heap without verifying that this size matches the originally allocated chunk.

As a result, we can overflow one chunk and corrupt the metadata of adjacent heap chunks.

#### Plan

To exploit this binary, we need to find a primitive that gives us an arbitrary `read/write`.

Since this challenge targets an older version of glibc (2.23), it does not include the `Thread Local Caching (tcache) Bin`, meaning allocations and frees follow the classic bin behavior (fastbin / unsorted bin / small bin / largebin).

Looking at the *write_chunk* function, we see a potential target for getting a libc leak (supposing we have *arb write*).

```c
  if ( strlen(chunk[idx]) <= 3 )
    puts("//TODO");
```

Basically if we can control what's stored in *chunk[idx]* and we can overwrite *strlen* then this means we can get a libc leak, as we can easily set the *GOT* of *strlen* to *puts@plt* and *chunk[idx]* to *puts@got*, essentially ending up being this:

```c
puts(puts)
```

This works well because there's no other references to *strlen*.

#### Heaps Of Fun

Note: This really isn't a detailed explanation on how the heap works...

When a program requests dynamic memory, the allocator extends the process’s data segment using the sbrk syscall, creating a region known as the heap. This region is managed internally by glibc using heap chunks and linked lists.

This is the structure of a chunk allocated by `malloc`.

```c
struct malloc_chunk {

  INTERNAL_SIZE_T      prev_size;  /* Size of previous chunk (if free).  */
  INTERNAL_SIZE_T      size;       /* Size in bytes, including overhead. */

  struct malloc_chunk* fd;         /* double links -- used only if free. */
  struct malloc_chunk* bk;

  /* Only used for large blocks: pointer to next larger size.  */
  struct malloc_chunk* fd_nextsize; /* double links -- used only if free. */
  struct malloc_chunk* bk_nextsize;
};
```

An allocated chunk looks like this:

```
    chunk-> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
	    |             Size of previous chunk, if allocated            | |
	    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
	    |             Size of chunk, in bytes                        M|P|
      mem-> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
	    |             User data starts here...                          .
	    .                                                               .
	    .             (malloc_usable_size() bytes)                      .
	    .                                                               |
nextchunk-> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
	    |             Size of chunk                                     |
	    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
```

This is how it looks like in memory when we allocate a chunk of `0x20` bytes.

```
0x603000|+0x00000|+0x00000: 0x0000000000000000 0x0000000000000031 | ........1....... |
0x603010|+0x00010|+0x00010: 0x0000004141414141 0x0000000000000000 | AAAAA........... |
0x603020|+0x00020|+0x00020: 0x0000000000000000 0x0000000000000000 | ................ |
0x603030|+0x00000|+0x00030: 0x0000000000000000 0x0000000000020fd1 | ................ |  <-  top
```

The bit flags of the size field holds:
- NON_MAIN_ARENA (A): if the chunk was obtained from a non-main arena.
- IS_MMAPPED (M): if the chunk was obtained with mmap().
- PREV_INUSE (P): when previous adjacent chunk in use.

```c
/* size field is or'ed with PREV_INUSE when previous adjacent chunk in use */
#define PREV_INUSE 0x1

/* extract inuse bit of previous chunk */
#define prev_inuse(p)       ((p)->size & PREV_INUSE)

/* size field is or'ed with IS_MMAPPED if the chunk was obtained with mmap() */
#define IS_MMAPPED 0x2

/* check for mmap()'ed chunk */
#define chunk_is_mmapped(p) ((p)->size & IS_MMAPPED)

/* size field is or'ed with NON_MAIN_ARENA if the chunk was obtained
   from a non-main arena.  This is only set immediately before handing
   the chunk to the user, if necessary.  */
#define NON_MAIN_ARENA 0x4

/* check for chunk from non-main arena */
#define chunk_non_main_arena(p) ((p)->size & NON_MAIN_ARENA)
```

Here we will focus on what happens when we free a chunk.

There's no function in the glibc source code called *free*, it's only an alias for the function *__libc_free*.

```c
strong_alias (__libc_free, __free) strong_alias (__libc_free, free)
```

When we call *free*, we pass the pointer which needs to be freed as the first parameter.

In glibc, the free function first checks the *__free_hook* pointer:
- __free_hook is a function pointer that glibc calls whenever free is invoked, if it is set.
- The hook is read atomically, and if it is non-null, the function pointer is called with the memory being freed as an argument.
- After the hook is executed the function returns.
- In exploitation, this hook (present in glibc < 2.34) is commonly used to gain code by overwriting *__free_hook* with system and freeing a chunk which has */bin/sh* as the first quadword.

```c
void
__libc_free (void *mem)
{
  mstate ar_ptr;
  mchunkptr p;                          /* chunk corresponding to mem */

  void (*hook) (void *, const void *)
    = atomic_forced_read (__free_hook);
  if (__builtin_expect (hook != NULL, 0))
    {
      (*hook)(mem, RETURN_ADDRESS (0));
      return;
    }

  if (mem == 0)                              /* free(0) has no effect */
    return;
```

If *__free_hook* is null:
- It converts our memory to a chunk, this is achieved by subtracting it with 0x10, see macro below.
- It then checks if the chunk was allocated via a call to *mmap*, and if it is, it unmaps it from memory.
- Else if that isn't the case, it gets the current arena pointer (which in this case would be the main arena) and calls the *_int_free* function.

```c

#define chunk2mem(p)   ((void*)((char*)(p) + 2*SIZE_SZ))
#define mem2chunk(mem) ((mchunkptr)((char*)(mem) - 2*SIZE_SZ))

  p = mem2chunk (mem);

  if (chunk_is_mmapped (p))                       /* release mmapped memory. */
    {
      /* see if the dynamic brk/mmap threshold needs adjusting */
      if (!mp_.no_dyn_threshold
          && p->size > mp_.mmap_threshold
          && p->size <= DEFAULT_MMAP_THRESHOLD_MAX)
        {
          mp_.mmap_threshold = chunksize (p);
          mp_.trim_threshold = 2 * mp_.mmap_threshold;
          LIBC_PROBE (memory_mallopt_free_dyn_thresholds, 2,
                      mp_.mmap_threshold, mp_.trim_threshold);
        }
      munmap_chunk (p);
      return;
    }

  ar_ptr = arena_for_chunk (p);
  _int_free (ar_ptr, p, 0);
}
```